{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths to the directories\n",
        "base_dir = '/project/msoleyma_1026/ecp/data'\n",
        "video_dir = os.path.join(base_dir, 'video/train')\n",
        "text_dir = os.path.join(base_dir, 'text/train-emotion')\n",
        "audio_dir = os.path.join(base_dir, 'audio/train-emotion')\n",
        "output_dir = os.path.join(base_dir, 'concatenated/train-emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure the output directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Load train data\n",
        "with open(os.path.join(base_dir, 'train.json'), 'r') as file:\n",
        "    train_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterate through each conversation\n",
        "for conversation in train_data:\n",
        "    for utterance in conversation['conversation']:\n",
        "        video_name = utterance['video_name']\n",
        "        base_name = video_name.replace('.mp4', '')\n",
        "\n",
        "        # Paths to the embeddings\n",
        "        video_path = os.path.join(video_dir, f'{base_name}.npy')\n",
        "        text_path = os.path.join(text_dir, f'{base_name}.npy')\n",
        "        audio_path = os.path.join(audio_dir, f'{base_name}.npy')\n",
        "\n",
        "        # Check if all files exist\n",
        "        if os.path.exists(video_path) and os.path.exists(text_path) and os.path.exists(audio_path):\n",
        "            # Load embeddings\n",
        "            video_emb = np.load(video_path)\n",
        "            text_emb = np.load(text_path)\n",
        "            audio_emb = np.load(audio_path)\n",
        "\n",
        "            # Concatenate embeddings\n",
        "            concatenated_emb = np.concatenate((video_emb, text_emb, audio_emb), axis=1)\n",
        "\n",
        "            # Ensure the concatenated embeddings are of the correct shape (1, 2560)\n",
        "            if concatenated_emb.shape == (1, 2560):\n",
        "                # Save the concatenated embeddings\n",
        "                save_path = os.path.join(output_dir, f'{base_name}_concatenated.npy')\n",
        "                np.save(save_path, concatenated_emb)\n",
        "            else:\n",
        "                print(f'Error: Concatenated shape mismatch at {base_name}')\n",
        "        else:\n",
        "            print(f'Missing files for {base_name}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths to the directories\n",
        "base_dir = '/project/msoleyma_1026/ecp/data'\n",
        "video_dir = os.path.join(base_dir, 'video/test')\n",
        "text_dir = os.path.join(base_dir, 'text/test-emotion')\n",
        "audio_dir = os.path.join(base_dir, 'audio/test-emotion')\n",
        "output_dir = os.path.join(base_dir, 'concatenated/test-emotion')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure the output directory exists\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Load train data\n",
        "with open(os.path.join(base_dir, 'test.json'), 'r') as file:\n",
        "    test_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Iterate through each conversation\n",
        "for conversation in test_data:\n",
        "    for utterance in conversation['conversation']:\n",
        "        video_name = utterance['video_name']\n",
        "        base_name = video_name.replace('.mp4', '')\n",
        "\n",
        "        # Paths to the embeddings\n",
        "        video_path = os.path.join(video_dir, f'{base_name}.npy')\n",
        "        text_path = os.path.join(text_dir, f'{base_name}.npy')\n",
        "        audio_path = os.path.join(audio_dir, f'{base_name}.npy')\n",
        "\n",
        "        # Check if all files exist\n",
        "        if os.path.exists(video_path) and os.path.exists(text_path) and os.path.exists(audio_path):\n",
        "            # Load embeddings\n",
        "            video_emb = np.load(video_path)\n",
        "            text_emb = np.load(text_path)\n",
        "            audio_emb = np.load(audio_path)\n",
        "\n",
        "            # Concatenate embeddings\n",
        "            concatenated_emb = np.concatenate((video_emb, text_emb, audio_emb), axis=1)\n",
        "\n",
        "            # Ensure the concatenated embeddings are of the correct shape (1, 2560)\n",
        "            if concatenated_emb.shape == (1, 2560):\n",
        "                # Save the concatenated embeddings\n",
        "                save_path = os.path.join(output_dir, f'{base_name}_concatenated.npy')\n",
        "                np.save(save_path, concatenated_emb)\n",
        "            else:\n",
        "                print(f'Error: Concatenated shape mismatch at {base_name}')\n",
        "        else:\n",
        "            print(f'Missing files for {base_name}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 2560)\n",
            "(1, 2560)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.load(\"/project/msoleyma_1026/ecp/data/concatenated/train-emotion/dia1utt1_concatenated.npy\")\n",
        "print(x.shape)\n",
        "\n",
        "y = np.load(\"/project/msoleyma_1026/ecp/data/concatenated/test-emotion/dia16utt1_concatenated.npy\")\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('/project/msoleyma_1026/ecp/data/utterance_pairs_emotion_flags_train.json', 'r') as f:\n",
        "    utterance_pairs_emotion_flags_train = json.load(f)\n",
        "with open('/project/msoleyma_1026/ecp/data/utterance_pairs_emotion_flags_test.json', 'r') as f:\n",
        "    utterance_pairs_emotion_flags_test = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_pairs(input_folder_path, utterance_pairs_emotion_flags, output_folder_path):\n",
        "    for conversation in utterance_pairs_emotion_flags:\n",
        "        conv_id = list(conversation.keys())[0]\n",
        "        for pair in conversation[conv_id]:\n",
        "            (utt1_id, utt2_id), emotion, flag = pair['utterance_pair'], pair['emotion'], pair['valid_pair']\n",
        "            utt1_embedding_filename = \"dia\" + str(conv_id) + \"utt\" + str(utt1_id)\n",
        "            utt1_embedding_path = os.path.join(input_folder_path, f'{utt1_embedding_filename}_concatenated.npy')\n",
        "            utt2_embedding_filename = \"dia\" + str(conv_id) + \"utt\" + str(utt2_id)\n",
        "            utt2_embedding_path = os.path.join(input_folder_path, f'{utt2_embedding_filename}_concatenated.npy')\n",
        "\n",
        "            utt1_embedding = np.load(utt1_embedding_path)\n",
        "            utt2_embedding = np.load(utt2_embedding_path)\n",
        "\n",
        "            combined_embedding = np.concatenate([utt1_embedding, utt2_embedding], axis=1)\n",
        "\n",
        "            output_filename = f'conv_{conv_id}_utterance_pair_{utt1_id}_{utt2_id}.npy'\n",
        "            if not os.path.exists(os.path.join(output_folder_path, output_filename)):\n",
        "              np.save(os.path.join(output_folder_path, output_filename), combined_embedding)\n",
        "\n",
        "concat_folder_path_train = '/project/msoleyma_1026/ecp/data/concatenated/train-emotion'\n",
        "concat_folder_path_test = '/project/msoleyma_1026/ecp/data/concatenated/test-emotion'\n",
        "concat_pair_embeddings_folder_path_train = '/project/msoleyma_1026/ecp/data/pair_embeddings/concatenated/train-emotion'\n",
        "concat_pair_embeddings_folder_path_test = '/project/msoleyma_1026/ecp/data/pair_embeddings/concatenated/test-emotion'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "process_pairs(concat_folder_path_train, utterance_pairs_emotion_flags_train, concat_pair_embeddings_folder_path_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "process_pairs(concat_folder_path_test, utterance_pairs_emotion_flags_test, concat_pair_embeddings_folder_path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 5120)\n",
            "(1, 5120)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.load(\"/project/msoleyma_1026/ecp/data/pair_embeddings/concatenated/train-emotion/conv_1_utterance_pair_3_1.npy\")\n",
        "print(x.shape)\n",
        "\n",
        "y = np.load(\"/project/msoleyma_1026/ecp/data/pair_embeddings/concatenated/test-emotion/conv_16_utterance_pair_1_1.npy\")\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
